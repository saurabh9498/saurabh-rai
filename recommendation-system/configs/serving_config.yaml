# =============================================================================
# Serving Configuration
# Inference and API settings for the recommendation system
# =============================================================================

# =============================================================================
# API Settings
# =============================================================================
api:
  host: "0.0.0.0"
  port: 8000
  workers: 4
  timeout_seconds: 10
  
  # Rate limiting
  rate_limit:
    enabled: true
    requests_per_second: 1000
    burst_size: 2000
  
  # CORS
  cors:
    enabled: true
    origins: ["*"]
    allow_credentials: true
    allow_methods: ["GET", "POST", "OPTIONS"]
    allow_headers: ["*"]
  
  # Request validation
  validation:
    max_recommendations: 100
    default_recommendations: 10
    max_batch_users: 100
    max_exclude_items: 500

# =============================================================================
# Retrieval Stage
# =============================================================================
retrieval:
  # Candidate count
  num_candidates: 1000
  
  # FAISS index
  faiss:
    index_path: "/models/faiss_index"
    index_type: "IVF4096,Flat"
    metric: "inner_product"
    nprobe: 64
    use_gpu: true
    
  # Caching
  cache:
    enabled: true
    ttl_seconds: 300
    max_size: 100000
    
  # Fallback strategies
  fallback:
    enabled: true
    strategy: "popular"  # popular, random, category_popular
    num_items: 100
    
  # Real-time filtering
  filters:
    exclude_out_of_stock: true
    exclude_recently_purchased: true
    recently_purchased_days: 30
    
  # Diversity
  diversity:
    enabled: true
    method: "mmr"  # mmr, category_spread
    lambda: 0.3
    max_same_category: 5

# =============================================================================
# Ranking Stage
# =============================================================================
ranking:
  # Model settings
  model:
    name: "dlrm"
    version: "latest"
    
  # Batching
  batch_size: 64
  max_batch_wait_ms: 5
  
  # Output
  top_k: 50
  
  # Multi-objective optimization
  objectives:
    ctr:
      weight: 0.5
    revenue:
      weight: 0.3
    diversity:
      weight: 0.2
      
  # Business rules (post-ranking)
  business_rules:
    # Boost new items
    new_item_boost:
      enabled: true
      days_threshold: 7
      boost_factor: 1.2
      
    # Boost discounted items
    discount_boost:
      enabled: true
      min_discount: 0.2
      boost_factor: 1.1
      
    # Demote low-stock items
    low_stock_penalty:
      enabled: true
      threshold: 5
      penalty_factor: 0.8

# =============================================================================
# Triton Inference Server
# =============================================================================
triton:
  url: "localhost:8001"
  protocol: "grpc"
  
  models:
    two_tower_user:
      name: "two_tower_user"
      version: "1"
      timeout_ms: 20
      
    two_tower_item:
      name: "two_tower_item"
      version: "1"
      timeout_ms: 20
      
    dlrm:
      name: "dlrm"
      version: "1"
      timeout_ms: 30
      
  # Client settings
  client:
    max_connections: 100
    connection_timeout_ms: 5000
    request_timeout_ms: 50

# =============================================================================
# Feature Store
# =============================================================================
feature_store:
  backend: "redis"
  
  redis:
    host: "${REDIS_HOST:localhost}"
    port: ${REDIS_PORT:6379}
    password: "${REDIS_PASSWORD:}"
    db: 0
    max_connections: 100
    socket_timeout: 5.0
    
  # Feature retrieval settings
  retrieval:
    batch_size: 100
    timeout_ms: 10
    retry_count: 2
    
  # Caching
  cache:
    user_features_ttl: 3600
    item_features_ttl: 86400
    context_features_ttl: 300

# =============================================================================
# A/B Testing
# =============================================================================
ab_testing:
  enabled: true
  default_variant: "control"
  
  # Bucketing
  bucketing:
    method: "user_id_hash"
    salt: "recommendation_ab_test"
    
  # Active experiments
  experiments:
    homepage_recs_v2:
      enabled: true
      variants:
        control:
          weight: 50
          model: "dlrm_v1"
        treatment:
          weight: 50
          model: "dlrm_v2"
      metrics:
        - ctr
        - revenue
        - session_duration

# =============================================================================
# Monitoring
# =============================================================================
monitoring:
  # Prometheus metrics
  metrics:
    enabled: true
    port: 9090
    path: "/metrics"
    
  # Latency tracking
  latency:
    buckets: [0.001, 0.005, 0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1.0]
    
  # Health checks
  health:
    path: "/health"
    include_dependencies: true
    
  # Logging
  logging:
    level: "INFO"
    format: "json"
    sample_rate: 0.01  # Log 1% of requests in detail

# =============================================================================
# Latency Budgets
# =============================================================================
latency_budgets:
  total_ms: 50
  
  breakdown:
    feature_retrieval_ms: 5
    candidate_retrieval_ms: 10
    ranking_ms: 20
    post_processing_ms: 5
    overhead_ms: 10
    
  # SLOs
  slo:
    p50_ms: 10
    p95_ms: 30
    p99_ms: 50
