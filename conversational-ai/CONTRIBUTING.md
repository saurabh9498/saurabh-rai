# Contributing to Conversational AI Assistant

Thank you for your interest in contributing to the Conversational AI Assistant! This document provides guidelines and instructions for contributing.

## Table of Contents

- [Code of Conduct](#code-of-conduct)
- [Getting Started](#getting-started)
- [Development Setup](#development-setup)
- [Project Structure](#project-structure)
- [Coding Standards](#coding-standards)
- [Testing Guidelines](#testing-guidelines)
- [Submitting Changes](#submitting-changes)
- [Review Process](#review-process)

---

## Code of Conduct

We are committed to providing a welcoming and inclusive environment. Please:

- Be respectful and constructive in discussions
- Welcome newcomers and help them get started
- Focus on what's best for the community
- Show empathy towards other community members

---

## Getting Started

### Prerequisites

- Python 3.9+
- Docker and Docker Compose
- FFmpeg (for audio processing)
- Git

### Fork and Clone

```bash
# Fork the repository on GitHub, then:
git clone https://github.com/YOUR_USERNAME/conversational-ai.git
cd conversational-ai
git remote add upstream https://github.com/ORIGINAL_OWNER/conversational-ai.git
```

---

## Development Setup

### 1. Create Virtual Environment

```bash
python -m venv venv
source venv/bin/activate  # Linux/Mac
# or
.\venv\Scripts\activate   # Windows
```

### 2. Install Dependencies

```bash
# Install main dependencies
pip install -r requirements.txt

# Install development dependencies
pip install -r requirements-dev.txt

# Or install in editable mode
pip install -e ".[dev]"
```

### 3. Install System Dependencies

```bash
# Ubuntu/Debian
sudo apt-get install ffmpeg libsndfile1 portaudio19-dev

# macOS
brew install ffmpeg portaudio

# Windows
# Download FFmpeg from https://ffmpeg.org/download.html
```

### 4. Set Up Pre-commit Hooks

```bash
pre-commit install
```

### 5. Configure Environment

```bash
cp .env.example .env
# Edit .env with your local settings
```

### 6. Download Models

```bash
# Download Whisper model for ASR
python -c "import whisper; whisper.load_model('base')"

# Download TTS model (optional)
python -c "from TTS.api import TTS; TTS('tts_models/en/ljspeech/tacotron2-DDC')"
```

---

## Project Structure

```
conversational-ai/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ api/              # FastAPI endpoints and WebSocket
â”‚   â”‚   â”œâ”€â”€ main.py       # Application entry point
â”‚   â”‚   â”œâ”€â”€ routes.py     # REST endpoints
â”‚   â”‚   â”œâ”€â”€ schemas.py    # Pydantic models
â”‚   â”‚   â””â”€â”€ websocket.py  # WebSocket handlers
â”‚   â”œâ”€â”€ asr/              # Automatic Speech Recognition
â”‚   â”‚   â”œâ”€â”€ whisper_asr.py    # Whisper integration
â”‚   â”‚   â”œâ”€â”€ audio_processor.py # Audio preprocessing
â”‚   â”‚   â”œâ”€â”€ streaming.py      # Streaming ASR
â”‚   â”‚   â””â”€â”€ vad.py            # Voice Activity Detection
â”‚   â”œâ”€â”€ nlu/              # Natural Language Understanding
â”‚   â”‚   â”œâ”€â”€ intent_classifier.py  # Intent detection
â”‚   â”‚   â”œâ”€â”€ entity_extractor.py   # NER
â”‚   â”‚   â”œâ”€â”€ pipeline.py           # NLU pipeline
â”‚   â”‚   â””â”€â”€ sentiment.py          # Sentiment analysis
â”‚   â”œâ”€â”€ dialog/           # Dialog Management
â”‚   â”‚   â”œâ”€â”€ state_tracker.py      # State tracking
â”‚   â”‚   â”œâ”€â”€ policy.py             # Dialog policy
â”‚   â”‚   â”œâ”€â”€ context_manager.py    # Context handling
â”‚   â”‚   â””â”€â”€ response_generator.py # Response generation
â”‚   â”œâ”€â”€ tts/              # Text-to-Speech
â”‚   â”‚   â”œâ”€â”€ synthesizer.py    # TTS synthesis
â”‚   â”‚   â”œâ”€â”€ ssml_parser.py    # SSML parsing
â”‚   â”‚   â””â”€â”€ audio_streamer.py # Audio streaming
â”‚   â””â”€â”€ utils/            # Utilities
â”‚       â”œâ”€â”€ audio.py      # Audio utilities
â”‚       â”œâ”€â”€ logging.py    # Logging config
â”‚       â””â”€â”€ metrics.py    # Prometheus metrics
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ unit/             # Unit tests
â”‚   â”œâ”€â”€ integration/      # Integration tests
â”‚   â””â”€â”€ conftest.py       # Pytest fixtures
â”œâ”€â”€ configs/              # Configuration files
â”œâ”€â”€ data/                 # Data and samples
â”œâ”€â”€ docker/               # Docker files
â”œâ”€â”€ docs/                 # Documentation
â”œâ”€â”€ notebooks/            # Jupyter notebooks
â””â”€â”€ scripts/              # Utility scripts
```

---

## Coding Standards

### Python Style

We follow PEP 8 with some modifications:

```python
# Good: Use type hints
def transcribe_audio(
    audio: np.ndarray,
    sample_rate: int = 16000,
    language: str = "en",
) -> TranscriptionResult:
    """Transcribe audio to text.
    
    Args:
        audio: Audio samples as numpy array
        sample_rate: Audio sample rate in Hz
        language: Language code (ISO 639-1)
        
    Returns:
        TranscriptionResult with text and metadata
    """
    ...

# Good: Use dataclasses for data structures
@dataclass
class TranscriptionResult:
    text: str
    confidence: float
    language: str
    segments: List[Segment]
```

### Code Formatting

```bash
# Format code
black src/ tests/ scripts/

# Sort imports
isort src/ tests/ scripts/

# Lint
ruff check src/ tests/ scripts/

# Type check
mypy src/
```

### Docstrings

Use Google-style docstrings:

```python
def process_utterance(
    text: str,
    session_id: str,
    context: Optional[Dict] = None,
) -> DialogResponse:
    """Process a user utterance and generate response.
    
    This function handles the complete NLU -> Dialog -> Response pipeline.
    
    Args:
        text: User's input text
        session_id: Unique session identifier
        context: Optional context from previous turns
        
    Returns:
        DialogResponse containing the assistant's response and updated state
        
    Raises:
        SessionNotFoundError: If session_id is invalid
        NLUError: If intent classification fails
        
    Example:
        >>> response = process_utterance("Book a flight to Paris", "sess_123")
        >>> print(response.text)
        "I'd be happy to help you book a flight to Paris..."
    """
```

---

## Testing Guidelines

### Running Tests

```bash
# Run all tests
pytest

# Run with coverage
pytest --cov=src --cov-report=html

# Run specific test file
pytest tests/unit/test_nlu.py -v

# Run tests matching pattern
pytest -k "test_intent" -v

# Run only unit tests
pytest tests/unit/ -v

# Run integration tests (requires services)
RUN_INTEGRATION_TESTS=true pytest tests/integration/ -v
```

### Writing Tests

```python
# tests/unit/test_nlu.py
import pytest
from src.nlu.intent_classifier import IntentClassifier

class TestIntentClassifier:
    """Tests for intent classification."""
    
    @pytest.fixture
    def classifier(self):
        """Create classifier instance."""
        return IntentClassifier(model_path="models/intent")
    
    def test_greeting_intent(self, classifier):
        """Test classification of greeting intents."""
        result = classifier.classify("Hello there!")
        
        assert result.intent == "greeting"
        assert result.confidence > 0.8
    
    @pytest.mark.parametrize("text,expected_intent", [
        ("Book a flight", "book_flight"),
        ("What's the weather", "check_weather"),
        ("Set a reminder", "set_reminder"),
    ])
    def test_various_intents(self, classifier, text, expected_intent):
        """Test multiple intent types."""
        result = classifier.classify(text)
        assert result.intent == expected_intent
```

### Test Coverage Requirements

- Minimum 70% overall coverage
- New features must include tests
- Critical paths require 90%+ coverage

---

## Submitting Changes

### Branch Naming

```
feature/add-multilingual-support
bugfix/fix-audio-buffer-overflow
docs/update-api-reference
refactor/simplify-dialog-state
```

### Commit Messages

Follow conventional commits:

```
feat(asr): add streaming transcription support

- Implement chunked audio processing
- Add Voice Activity Detection
- Support real-time partial results

Closes #123
```

Types: `feat`, `fix`, `docs`, `style`, `refactor`, `test`, `chore`

### Pull Request Process

1. **Create feature branch**
   ```bash
   git checkout -b feature/your-feature
   ```

2. **Make changes and commit**
   ```bash
   git add .
   git commit -m "feat(component): description"
   ```

3. **Keep branch updated**
   ```bash
   git fetch upstream
   git rebase upstream/main
   ```

4. **Push and create PR**
   ```bash
   git push origin feature/your-feature
   # Open PR on GitHub
   ```

5. **PR Template**
   ```markdown
   ## Description
   Brief description of changes
   
   ## Type of Change
   - [ ] Bug fix
   - [ ] New feature
   - [ ] Breaking change
   - [ ] Documentation
   
   ## Testing
   - [ ] Unit tests added/updated
   - [ ] Integration tests added/updated
   - [ ] Manual testing completed
   
   ## Checklist
   - [ ] Code follows style guidelines
   - [ ] Self-review completed
   - [ ] Documentation updated
   - [ ] No new warnings
   ```

---

## Review Process

### What We Look For

1. **Functionality**: Does it work correctly?
2. **Tests**: Are changes well-tested?
3. **Performance**: Any performance implications?
4. **Security**: Any security concerns?
5. **Documentation**: Is it documented?
6. **Style**: Does it follow our standards?

### Timeline

- Initial review: 2-3 business days
- Follow-up reviews: 1-2 business days
- Complex changes may take longer

---

## Component-Specific Guidelines

### ASR (Speech Recognition)

- Test with various audio qualities
- Consider different accents/languages
- Validate sample rate handling
- Test streaming edge cases

### NLU (Natural Language Understanding)

- Include diverse training examples
- Test entity extraction thoroughly
- Validate confidence thresholds
- Consider edge cases (empty input, very long input)

### Dialog Management

- Test multi-turn conversations
- Validate state persistence
- Test slot filling logic
- Consider context window limits

### TTS (Text-to-Speech)

- Test various text inputs
- Validate SSML parsing
- Check audio quality
- Test streaming output

---

## Getting Help

- **Questions**: Open a GitHub Discussion
- **Bugs**: Open a GitHub Issue
- **Features**: Open a Feature Request issue
- **Security**: Email security@example.com

---

## Recognition

Contributors will be:
- Listed in CONTRIBUTORS.md
- Mentioned in release notes
- Thanked in documentation

Thank you for contributing! ðŸŽ‰
